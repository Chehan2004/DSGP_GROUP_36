{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setup and Data Collection\n",
   "id": "32debb84780e2ef9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd # Used for creating clear tables/metrics\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ==============================================================================\n",
    "# Set this path to your new balanced dataset folder\n",
    "data_dir = Path(r'D:\\YV\\DSGP-IIT\\disease and pest detection\\Augmented_for_ml')\n",
    "\n",
    "# Set the TARGET_COUNT used in your augmentation script for comparison\n",
    "TARGET_COUNT = 1300\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Collect Counts and Metrics\n",
    "# ==============================================================================\n",
    "\n",
    "class_counts = {}\n",
    "total_images = 0\n",
    "\n",
    "# Get a list of all class folders\n",
    "class_folders = [d for d in data_dir.iterdir() if d.is_dir()]\n",
    "\n",
    "# Iterate and count images in each folder\n",
    "for class_path in class_folders:\n",
    "    class_name = class_path.name\n",
    "    # Use glob('*') to count all files in the directory\n",
    "    count = len(list(class_path.glob('*')))\n",
    "    class_counts[class_name] = count\n",
    "    total_images += count\n",
    "\n",
    "print(\"--- Class Distribution Analysis (Post-Augmentation) ---\")\n",
    "print(f\"Total Images in Dataset: {total_images}\")\n",
    "print(f\"Goal Count per Class: {TARGET_COUNT}\")"
   ],
   "id": "7e4119b74f247b01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Metrics Table",
   "id": "486fa5b7ad74ae90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a DataFrame for easy metric calculation and display\n",
    "df_metrics = pd.DataFrame.from_dict(class_counts, orient='index', columns=['Final Count'])\n",
    "\n",
    "# Calculate the deviation from the target\n",
    "df_metrics['Target Count'] = TARGET_COUNT\n",
    "df_metrics['Difference'] = df_metrics['Final Count'] - df_metrics['Target Count']\n",
    "\n",
    "# Calculate the percentage of total images\n",
    "df_metrics['% of Total'] = (df_metrics['Final Count'] / total_images) * 100\n",
    "\n",
    "# Sort by count for better comparison\n",
    "df_metrics = df_metrics.sort_values(by='Final Count', ascending=False)\n",
    "\n",
    "# Display the metrics table\n",
    "print(\"\\n--- Balance Metrics Table ---\")\n",
    "# Use Markdown formatting to display the table clearly in the notebook\n",
    "display(df_metrics.style.format({'Final Count': '{:,}', 'Target Count': '{:,}', '% of Total': '{:.2f}%'}))"
   ],
   "id": "e3df95c3af54e56b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualization",
   "id": "2bfd552aa931d812"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare data for plotting\n",
    "classes = list(df_metrics.index)\n",
    "counts = df_metrics['Final Count'].tolist()\n",
    "y_pos = np.arange(len(classes))\n",
    "\n",
    "# Define colors based on target count\n",
    "colors = ['lightcoral' if count < TARGET_COUNT else 'skyblue' for count in counts]\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "bars = plt.barh(y_pos, counts, align='center', color=colors)\n",
    "\n",
    "# Add a vertical line to represent the target count\n",
    "plt.axvline(TARGET_COUNT, color='green', linestyle='--', linewidth=1.5, label=f'Target ({TARGET_COUNT})')\n",
    "\n",
    "plt.yticks(y_pos, classes)\n",
    "plt.xlabel('Number of Images', fontsize=12)\n",
    "plt.title('Post-Augmentation Image Distribution per Disease Class (Balanced Dataset)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(axis='x', linestyle=':', alpha=0.7)\n",
    "\n",
    "# Add data labels to the bars\n",
    "for bar in bars:\n",
    "    plt.text(bar.get_width() + 50, bar.get_y() + bar.get_height()/2,\n",
    "             f'{bar.get_width():,}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Assuming 'history' is the object returned by model.fit()\n",
    "def plot_training_history(history):\n",
    "    # --- Plot 1: Loss ---\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Curve Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "# Example usage (assuming class labels are ['Healthy', 'Blister Blight', 'Rust']):\n",
    "# plot_confusion_matrix(y_true, y_pred_classes, class_labels=['Healthy', 'BB', 'Rust'])\n"
   ],
   "id": "6ad751731c3bfc58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Feature Extraction Script(VGG16 transfer learning)",
   "id": "bc4bb7efc74dd077"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ==============================================================================\n",
    "\n",
    "# Directory containing the balanced dataset (output of your augmentation script)\n",
    "data_dir = Path(r'D:\\YV\\DSGP-IIT\\disease and pest detection\\augmented_for_ml')\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# Location to save the final feature arrays\n",
    "save_location = data_dir.parent\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. SETUP VGG16 AS THE FEATURE EXTRACTOR\n",
    "# ==============================================================================\n",
    "\n",
    "# Load VGG16 pre-trained on ImageNet weights\n",
    "# include_top=False tells Keras to remove the final classification layers,\n",
    "# leaving only the deep feature-extracting layers.\n",
    "print(\"Loading VGG16 Feature Extractor...\")\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
    ")\n",
    "\n",
    "# Create the final feature extractor model structure:\n",
    "# 1. Base VGG16 Layers (extracts features)\n",
    "# 2. GlobalAveragePooling2D (flattens the feature maps into a 1D vector of fixed size)\n",
    "feature_extractor = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D()\n",
    "])\n",
    "\n",
    "\n",
    "# Data structures to store the results\n",
    "features_list = []\n",
    "labels_list = []\n",
    "class_to_index = {}\n",
    "current_index = 0\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. EXTRACT FEATURES FROM BALANCED IMAGES\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Starting Feature Extraction Process (Time-consuming step) ---\")\n",
    "\n",
    "for class_path in data_dir.iterdir():\n",
    "    if class_path.is_dir():\n",
    "        class_name = class_path.name\n",
    "        print(f\"Processing class: {class_name}\")\n",
    "\n",
    "        # Map class name to a numerical index (0, 1, 2, ...)\n",
    "        if class_name not in class_to_index:\n",
    "            class_to_index[class_name] = current_index\n",
    "            current_index += 1\n",
    "\n",
    "        label = class_to_index[class_name]\n",
    "\n",
    "        # Loop through all image files in the class folder\n",
    "        image_files = list(class_path.glob('*'))\n",
    "\n",
    "        # Use tqdm for a visible progress bar in your notebook\n",
    "        for img_path in tqdm(image_files):\n",
    "            try:\n",
    "                # Load and preprocess the image\n",
    "                img = image.load_img(img_path, target_size=IMAGE_SIZE)\n",
    "                img_array = image.img_to_array(img)\n",
    "                img_array = np.expand_dims(img_array, axis=0) # Add batch dimension\n",
    "\n",
    "                # Apply VGG16-specific preprocessing\n",
    "                img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
    "\n",
    "                # Extract features using the model\n",
    "                features = feature_extractor.predict(img_array, verbose=0)\n",
    "\n",
    "                # Append the flattened feature vector and label\n",
    "                features_list.append(features.flatten())\n",
    "                labels_list.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping corrupted file {img_path.name} in {class_name}: {e}\")\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X = np.array(features_list)\n",
    "y = np.array(labels_list)\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. SAVE RESULTS\n",
    "# ==============================================================================\n",
    "\n",
    "# Save the features and labels to disk for final model training\n",
    "np.save(save_location / 'extracted_features_X.npy', X)\n",
    "np.save(save_location / 'extracted_labels_y.npy', y)\n",
    "np.save(save_location / 'class_mapping.npy', class_to_index)\n",
    "\n",
    "print(f\"\\nFeature Extraction Complete.\")\n",
    "print(f\"Shape of Features (X): {X.shape} (Total Images x Feature Vector Size)\")\n",
    "print(f\"Shape of Labels (y): {y.shape}\")\n",
    "print(f\"Features saved successfully to: {save_location.resolve()}\")"
   ],
   "id": "a75a5191e61cf19d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Correlation Matrix for Extracted features",
   "id": "787b7bd8df6c6841"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA # Required for better visualization\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURATION AND DATA LOADING\n",
    "# ==============================================================================\n",
    "\n",
    "# Location where features and labels were saved\n",
    "data_save_location = Path(r'D:\\YV\\DSGP-IIT\\disease and pest detection')\n",
    "\n",
    "# Load the saved feature arrays\n",
    "X = np.load(data_save_location / 'extracted_features_X.npy')\n",
    "y = np.load(data_save_location / 'extracted_labels_y.npy')\n",
    "class_map = np.load(data_save_location / 'class_mapping.npy', allow_pickle=True).item()\n",
    "index_to_class = {v: k for k, v in class_map.items()}\n",
    "\n",
    "print(\"Features Loaded. Shape of X:\", X.shape)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. DIMENSIONALITY REDUCTION (CRUCIAL STEP FOR VISUALIZATION)\n",
    "# ==============================================================================\n",
    "\n",
    "# The VGG16 features (X) have a very high dimension (e.g., 512 or 2048).\n",
    "# Calculating a correlation matrix on all dimensions is computationally huge and unreadable.\n",
    "# We must use Principal Component Analysis (PCA) to reduce the features to a manageable number (e.g., 20 components)\n",
    "# while retaining most of the variance.\n",
    "\n",
    "N_COMPONENTS = 20 # Number of principal components to keep for visualization\n",
    "\n",
    "print(f\"\\nApplying PCA to reduce feature dimensions from {X.shape[1]} to {N_COMPONENTS}...\")\n",
    "\n",
    "pca = PCA(n_components=N_COMPONENTS)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(f\"PCA Variance Explained by {N_COMPONENTS} components: {np.sum(pca.explained_variance_ratio_):.2f}\")\n",
    "\n",
    "# Convert the PCA features and labels into a single DataFrame\n",
    "feature_names = [f'PC_{i+1}' for i in range(N_COMPONENTS)]\n",
    "df_features = pd.DataFrame(X_pca, columns=feature_names)\n",
    "df_features['Target_Label'] = y # Add the numerical labels\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. CORRELATION MATRIX CALCULATION AND VISUALIZATION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\nCalculating Correlation Matrix...\")\n",
    "\n",
    "# Calculate the correlation matrix for the PCA components and the target label\n",
    "correlation_matrix = df_features.corr()\n",
    "\n",
    "# Extract only the correlation values we care about: Feature vs Feature, and Feature vs Target\n",
    "# Focus on the correlations between the top 20 features and the Target_Label\n",
    "target_correlations = correlation_matrix.loc[feature_names, 'Target_Label'].sort_values(ascending=False)\n",
    "feature_vs_feature_matrix = correlation_matrix.iloc[:-1, :-1] # Exclude the target row/column\n",
    "\n",
    "# --- VISUALIZATION 1: Feature vs Feature Correlation Heatmap ---\n",
    "plt.figure(figsize=(10, 8))\n",
    "#\n",
    "sns.heatmap(\n",
    "    feature_vs_feature_matrix,\n",
    "    annot=False, # Set to False as 20 values is still too many to read\n",
    "    fmt=\".2f\",\n",
    "    cmap='coolwarm',\n",
    "    linewidths=0.5\n",
    ")\n",
    "plt.title('Correlation Matrix of Principal Components (Feature vs. Feature)')\n",
    "plt.show()\n",
    "\n",
    "# --- VISUALIZATION 2: Feature vs Target Correlation Bar Plot ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "target_correlations.plot(kind='bar', color=target_correlations.apply(lambda x: 'salmon' if x < 0 else 'skyblue'))\n",
    "plt.title('Correlation of PCA Components with Disease Label (Target)')\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c4e6197f087a995a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
